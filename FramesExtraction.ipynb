{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEf52GAE3_Ii",
        "outputId": "f4167bd8-d0b5-4307-d31c-1cefa7d8c898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckMCM34b94Pp",
        "outputId": "6f90a407-295c-4eed-91df-b57bab5dea20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import face_recognition\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_face_frames_from_videos(video_folder, output_folder, label, max_frames_per_video=10):\n",
        "    os.makedirs(os.path.join(output_folder, label), exist_ok=True)\n",
        "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "\n",
        "    for video_file in tqdm(video_files, desc=f\"Processing {label} videos\"):\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        interval = max(1, frame_count // max_frames_per_video)\n",
        "\n",
        "        saved = 0\n",
        "        frame_no = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret or saved >= max_frames_per_video:\n",
        "                break\n",
        "\n",
        "            if frame_no % interval == 0:\n",
        "                rgb_frame = frame[:, :, ::-1]\n",
        "                faces = face_recognition.face_locations(rgb_frame)\n",
        "\n",
        "                if faces:\n",
        "                    top, right, bottom, left = faces[0]  # Take first face\n",
        "                    face_img = rgb_frame[top:bottom, left:right]\n",
        "                    face_img = cv2.resize(face_img, (224, 224))\n",
        "\n",
        "                    save_path = os.path.join(output_folder, label, f\"{video_file[:-4]}_frame{saved}.jpg\")\n",
        "                    cv2.imwrite(save_path, cv2.cvtColor(face_img, cv2.COLOR_RGB2BGR))\n",
        "                    saved += 1\n",
        "\n",
        "            frame_no += 1\n",
        "\n",
        "        cap.release()\n"
      ],
      "metadata": {
        "id": "OOWMO2jQ9w3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_face_frames_from_videos('/content/drive/MyDrive/FF/real', '/content/drive/MyDrive/output', 'real')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHZz9po-9zej",
        "outputId": "0c1ae0d5-0a9c-4d31-ada3-261f0222dbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing real videos: 100%|██████████| 200/200 [1:03:25<00:00, 19.03s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_face_frames_from_videos('/content/drive/MyDrive/FF/fake', '/content/drive/MyDrive/output', 'fake')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vAFaL4b-pVM",
        "outputId": "9c061edc-3142-4944-9296-48b4a5f2f4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing fake videos: 100%|██████████| 200/200 [59:04<00:00, 17.72s/it]\n"
          ]
        }
      ]
    }
  ]
}